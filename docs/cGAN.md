# Conditional Generative Adversarial Network, cGAN

是生成对抗网络（GAN）的扩展版本，它在生成器和判别器中都引入了条件信息（例如标签）。cGAN 的目标是生成符合特定条件的图像，并且判别器需要根据条件信息来区分真实数据和生成数据

## cGAN 的基本原理

1. **真实数据分布**：
   - 真实数据有一个分布，称为真实数据分布 $ P_{data} $。

2. **生成器（Generator）**：
   - 生成器接受一个来自固定分布（通常是标准正态分布）的随机噪声向量 $ z $ 和条件标签 $ y $ 作为输入。
   - 生成器通过学习将这个随机噪声向量 $ z $ 和条件标签 $ y $ 转换为接近真实数据分布 $ P_{data} $ 的生成数据分布 $ P_{g} $。

3. **判别器（Discriminator）**：
   - 判别器接受一个数据样本（数据分布，例如：$ P_{data} $ 或 $ P_{g} $）和条件标签 $ y $ 作为输入，并输出一个概率值，表示该样本是真实数据的概率。
   - 判别器的目标是区分真实数据（来自 $ P_{data} $）和生成数据（来自 $ P_{g} $），即希望输入为 $ P_{data} $ 时输出为 1，输入为 $ P_{g} $ 时输出为 0。

## cGAN 的训练过程
cGAN 的训练过程与 GAN 类似，也是一个博弈过程，生成器和判别器交替训练，直到达到一个平衡状态。

### 1. 初始化
- 初始化生成器和判别器的参数。
- 定义损失函数（例如，二元交叉熵损失）。
- 定义优化器（例如，Adam 优化器）。

### 2. 训练判别器
- **输入**：真实数据（$ P_{data} $）和生成数据（$ P_{g} $），以及对应的条件标签 $ y $。
- **目标**：最大化判别器对真实数据的输出，同时最小化判别器对生成数据的输出。
- **步骤**：
  1. 从真实数据集中采样一批真实数据及其标签。
  2. 计算判别器对真实数据的损失。
  3. 从生成器生成的数据中采样一批假数据及其标签。
  4. 计算判别器对假数据的损失。
  5. 计算判别器的总损失。
  6. 反向传播并更新判别器的参数（梯度下降和权重更新）。

### 3. 训练生成器
- **输入**：随机噪声向量 $ z $ 和条件标签 $ y $。
- **目标**：最小化判别器对生成数据的输出，使判别器认为生成数据是真实的。
- **步骤**：
  1. 生成一批假数据（$ P_{g} $）及其标签。
  2. 从判别器拿到对假数据的判断。
  3. 计算生成器的损失。
  4. 反向传播并更新生成器的参数。

## cGAN 的损失函数
在条件生成对抗网络（cGAN）的训练过程中，判别器和生成器的损失分别使用不同的公式进行计算。通常使用二元交叉熵损失（Binary Cross-Entropy Loss）来计算这两个损失。

### 判别器的损失
判别器的总损失可以表示为：

$$
\begin{aligned}
l_i(x_i, y_i) &= -w_i \left[ y_i \cdot \log x_i + (1 - y_i) \cdot \log (1 - x_i) \right] \\
L_D &= \frac{1}{m} \sum_{i=1}^{m} \frac{1}{2} \left[ l_i(D(x^{(i)}, y^{(i)}), 1) + l_i(D(G(z^{(i)}, y^{(i)}), y^{(i)}), 0) \right] \\
&= -\frac{1}{m} \sum_{i=1}^{m} \frac{1}{2} \left[ \log D(x^{(i)}, y^{(i)}) + \log (1 - D(G(z^{(i)}, y^{(i)}), y^{(i)})) \right]
\end{aligned}
$$

其中：
- $ D(x^{(i)}, y^{(i)}) $ 是判别器对真实数据 $ x^{(i)} $ 和条件标签 $ y^{(i)} $ 的输出，$ x \in P_{data} $。
- $ D(G(z^{(i)}, y^{(i)}), y^{(i)}) $ 是判别器对生成数据 $ G(z^{(i)}, y^{(i)}) $ 和条件标签 $ y^{(i)} $ 的输出，$ z \in P_{g} $。
- $ m $ 是批次大小。

1. **单个样本的损失**：
   - 对于真实数据 $ x_i $ 和生成数据 $ G(z_i) $，损失函数 $ l_i $ 定义为：
     $$
     l_i(x_i, y_i) = -w_i \left[ y_i \cdot \log x_i + (1 - y_i) \cdot \log (1 - x_i) \right]
     $$

2. **真实数据的损失**：
   - 判别器希望对真实数据的输出接近 1。
   - 对于真实数据 $ x^{(i)} $，真实标签 $ y_i = 1 $：
     $$
     l_i(D(x^{(i)}, y^{(i)}), 1) = -\log D(x^{(i)}, y^{(i)})
     $$

3. **生成数据的损失**：
   - 判别器希望对生成数据的输出接近 0。
   - 对于生成数据 $ G(z^{(i)}, y^{(i)}) $，真实标签 $ y_i = 0 $：
     $$
     l_i(D(G(z^{(i)}, y^{(i)}), y^{(i)}), 0) = -\log (1 - D(G(z^{(i)}, y^{(i)}), y^{(i)}))
     $$

4. **判别器的总损失**：
   - 判别器的总损失是对真实数据和生成数据的损失的平均值：
     $$
     \begin{aligned}
     L_D &= \frac{1}{m} \sum_{i=1}^{m} \frac{1}{2} \left[ l_i(D(x^{(i)}, y^{(i)}), 1) + l_i(D(G(z^{(i)}, y^{(i)}), y^{(i)}), 0) \right] \\
     &= -\frac{1}{m} \sum_{i=1}^{m} \frac{1}{2} \left[ \log D(x^{(i)}, y^{(i)}) + \log (1 - D(G(z^{(i)}, y^{(i)}), y^{(i)})) \right]
     \end{aligned}
     $$

### 生成器的损失

生成器的目标是生成逼真的数据，使得判别器无法区分这些数据和真实数据。生成器的损失是判别器对生成数据的输出与真实标签（1）之间的二元交叉熵损失。

生成器的损失可以表示为：

$$
\begin{aligned}
L_G &= -\frac{1}{m} \sum_{i=1}^{m} l_i(D(G(z^{(i)}, y^{(i)}), y^{(i)}), 1) \\
&= -\frac{1}{m} \sum_{i=1}^{m} \log D(G(z^{(i)}, y^{(i)}), y^{(i)})
\end{aligned}
$$

其中：

- $ D(G(z^{(i)}, y^{(i)}), y^{(i)}) $ 是判别器对生成数据 $ G(z^{(i)}, y^{(i)}) $ 和条件标签 $ y^{(i)} $ 的输出。
- $ m $ 是批次大小
