{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络（Neural Network）是一种模拟生物神经系统的计算模型，广泛应用于机器学习和人工智能领域。神经网络由多个神经元（Neuron）组成，这些神经元通过连接（Connection）形成网络结构。以下是神经网络的基本概念和原理。\n",
    "\n",
    "### 神经网络的基本概念\n",
    "\n",
    "1. **神经元（Neuron）**：\n",
    "   - 神经元是神经网络的基本单位，类似于生物神经元。\n",
    "   - 每个神经元接收多个输入信号，通过加权求和和激活函数处理后，输出一个信号。\n",
    "\n",
    "2. **权重（Weight）**：\n",
    "   - 权重是连接神经元的参数，表示输入信号的重要性。\n",
    "   - 权重在训练过程中不断调整，以最小化损失函数。\n",
    "\n",
    "3. **偏置（Bias）**：\n",
    "   - 偏置是一个额外的参数，用于调整神经元的输出。\n",
    "   - 偏置在训练过程中也会不断调整。\n",
    "\n",
    "4. **激活函数（Activation Function）**：\n",
    "   - 激活函数用于引入非线性，使神经网络能够处理复杂的非线性问题。\n",
    "   - 常见的激活函数包括 Sigmoid、ReLU（Rectified Linear Unit）、Tanh 等。\n",
    "\n",
    "5. **层（Layer）**：\n",
    "   - 神经网络由多个层组成，每层包含多个神经元。\n",
    "   - 输入层（Input Layer）：接收输入数据。\n",
    "   - 隐藏层（Hidden Layer）：处理输入数据，提取特征。\n",
    "   - 输出层（Output Layer）：输出预测结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神经网络的工作原理\n",
    "\n",
    "1. **前向传播（Forward Propagation）**：\n",
    "   - 输入数据通过输入层传递到隐藏层，再通过隐藏层传递到输出层。\n",
    "   - 每个神经元计算输入信号的加权和，经过激活函数处理后输出信号。\n",
    "   - 输出层的输出即为神经网络的预测结果。\n",
    "\n",
    "2. **损失函数（Loss Function）**：\n",
    "   - 损失函数用于衡量神经网络的预测结果与真实值之间的差异。\n",
    "   - 常见的损失函数包括均方误差（Mean Squared Error, MSE）、交叉熵损失（Cross-Entropy Loss）等。\n",
    "\n",
    "3. **反向传播（Backward Propagation）**：\n",
    "   - 反向传播用于计算损失函数相对于每个权重和偏置的梯度。\n",
    "   - 通过链式法则，梯度从输出层逐层传递到输入层。\n",
    "\n",
    "4. **梯度下降（[Gradient Descent](./Gradient_Descent.ipynb)）**：\n",
    "   - 梯度下降用于更新权重和偏置，以最小化损失函数。\n",
    "   - 常见的梯度下降算法包括批量梯度下降（Batch Gradient Descent）、随机梯度下降（Stochastic Gradient Descent, SGD）和小批量梯度下降（Mini-Batch Gradient Descent）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神经网络的训练过程\n",
    "\n",
    "1. **初始化**：\n",
    "   - 初始化神经网络的权重和偏置。\n",
    "\n",
    "2. **前向传播**：\n",
    "   - 输入数据通过神经网络，计算输出结果。\n",
    "\n",
    "3. **计算损失**：\n",
    "   - 使用损失函数计算预测结果与真实值之间的差异。\n",
    "\n",
    "4. **反向传播**：\n",
    "   - 计算损失函数相对于每个权重和偏置的梯度。\n",
    "\n",
    "5. **更新参数**：\n",
    "   - 使用梯度下降算法更新权重和偏置。\n",
    "\n",
    "6. **重复**：\n",
    "   - 重复前向传播、计算损失、反向传播和更新参数的过程，直到损失函数收敛或达到预定的训练轮数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码示例: 用神经网络识别 MNIST 手写数字 的类别(标签, 0-9)\n",
    "\n",
    "对于 [MNIST 数据集](./MNIST_dataset.ipynb#MNIST-dataset-shape) 的单个图像的形状是 [1,28,28],展平为向量后形状为 [784], 作为神经网络的输入.\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x_0 \\\\\n",
    "x_1  \\\\\n",
    "x_2  \\\\\n",
    "\\vdots \\\\\n",
    "x_{783}  \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "输入层: 784个输入神经元, 隐藏层: 建议选择:一层,256个神经元, 输出层: 10个神经元, 分别对应0-9的数字."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1792x28 and 784x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 60\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# 内层循环使用 train_loader 加载数据, 进行小批量的数据读取\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (images, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;66;03m# if i == 3: # 为了快速验证代码的正确性，只迭代3次\u001b[39;00m\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;66;03m#     break\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;66;03m# images = images.view(-1, 28*28) # .shape = (64, 784)\u001b[39;00m\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;66;03m# print(images.shape) \u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 1.前向传播: 计算输出\u001b[39;00m\n\u001b[0;32m     61\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels) \u001b[38;5;66;03m# 2.计算输出和标签之间的损失\u001b[39;00m\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;66;03m# 这三步的顺序\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 32\u001b[0m, in \u001b[0;36mSimpleNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 32\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m     34\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(out)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1792x28 and 784x256)"
     ]
    }
   ],
   "source": [
    "# 1. 导入必要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 2. 定义数据预处理和加载数据\n",
    "# 定义数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将图像转换为张量\n",
    "    transforms.Normalize((0.5,), (0.5,))  # 归一化到 [-1, 1]\n",
    "])\n",
    "\n",
    "# 加载训练集和测试集\n",
    "train_dataset = datasets.MNIST(root='../data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='../data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 3. 定义神经网络模型\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# 超参数\n",
    "input_size = 784  # 输入层大小（28x28 的图像展平为向量）\n",
    "hidden_size = 256  # 隐藏层大小\n",
    "output_size = 10  # 输出层大小（10 个类别）\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "# 4. 初始化模型、损失函数和优化器\n",
    "model = SimpleNN(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# 5. 训练神经网络\n",
    "for epoch in range(epochs):\n",
    "    # 内层循环使用 train_loader 加载数据, 进行小批量的数据读取\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # if i == 3: # 为了快速验证代码的正确性，只迭代3次\n",
    "        #     break\n",
    "        # 内层每次迭代时，都会进行一次 梯度下降算法, 包括5个步骤\n",
    "        # 将图像展平为向量\n",
    "        # print(f\"batch_idx: {i}, images.shape: {images.shape}, labels.shape: {labels.shape}\")\n",
    "        # print(f\"labels: {labels}\")\n",
    "        images = images.view(-1, 28*28) # .shape = (64, 784)\n",
    "        # print(images.shape) \n",
    "        \n",
    "        outputs = model(images) # 1.前向传播: 计算输出\n",
    "        loss = criterion(outputs, labels) # 2.计算输出和标签之间的损失\n",
    "\n",
    "        # 这三步的顺序\n",
    "        optimizer.zero_grad() # 3.梯度清零: 以确保每次计算梯度时不会累加上一次计算的梯度\n",
    "        loss.backward() # 4.反向传播: 计算梯度\n",
    "        optimizer.step() # 5.更新参数\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "# 保存模型\n",
    "simple_nn_model_dir = '../output/weights/simple_nn_model/'\n",
    "torch.save(model.state_dict(), simple_nn_model_dir + 'simple_nn_model.pth')\n",
    "# 6. 评估神经网络\n",
    "# 评估模型在测试集上的性能\n",
    "model.eval()  # 设置模型为评估模式\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(-1, 28*28)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the model on the 10000 test images: {100 * correct / total:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vits_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
